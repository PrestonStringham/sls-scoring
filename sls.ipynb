{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719597c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "tf.config.optimizer.set_jit(True)\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87156a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ba7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_score_df(path):\n",
    "    files = [f for f in glob.glob(path + \"*\")]\n",
    "    scores = []\n",
    "    for i in files:\n",
    "        scores.append(float(i[5:8]))\n",
    "    return pd.DataFrame(files,scores).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b95b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = files_to_score_df('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b89bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.1</td>\n",
       "      <td>data\\9.1-SLSSC2019.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.1</td>\n",
       "      <td>data\\9.1-SLSSC2019.mov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       0\n",
       "0    9.1  data\\9.1-SLSSC2019.avi\n",
       "1    9.1  data\\9.1-SLSSC2019.mov"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a2103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\9.1-SLSSC2019.mov'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.iloc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fccf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Empty List declared to store video frames\n",
    "    frames_list = []\n",
    "    \n",
    "    # Reading the Video File Using the VideoCapture\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Iterating through Video Frames\n",
    "    while True:\n",
    "\n",
    "        # Reading a frame from the video file \n",
    "        success, frame = video_reader.read() \n",
    "    \n",
    "        # If Video frame was not successfully read then break the loop\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = gray / 255\n",
    "        \n",
    "        # Appending the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    # Closing the VideoCapture object and releasing all resources. \n",
    "    video_reader.release()\n",
    "\n",
    "    # returning the frames list \n",
    "    return frames_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475210f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame([[frames_extraction(score_df.iloc[1][0])]], np.array([score_df.iloc[1]['index']])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c3c3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.iloc[0][0]\n",
    "y = test_df.iloc[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7946def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca74a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb197e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6941cdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.0745098 , 0.07058824, 0.06666667, ..., 0.18431373,\n",
       "          0.18431373, 0.18823529],\n",
       "         [0.09411765, 0.09803922, 0.09803922, ..., 0.1372549 ,\n",
       "          0.1372549 , 0.1372549 ],\n",
       "         [0.0627451 , 0.06666667, 0.06666667, ..., 0.19607843,\n",
       "          0.2       , 0.19607843],\n",
       "         ...,\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ],\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ],\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ]],\n",
       "\n",
       "        [[0.08627451, 0.08627451, 0.08627451, ..., 0.12156863,\n",
       "          0.12156863, 0.11764706],\n",
       "         [0.07058824, 0.07058824, 0.06666667, ..., 0.19215686,\n",
       "          0.19215686, 0.19215686],\n",
       "         [0.07843137, 0.0745098 , 0.0745098 , ..., 0.1254902 ,\n",
       "          0.12156863, 0.11764706],\n",
       "         ...,\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ],\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.74117647,\n",
       "          0.74117647, 0.74117647],\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ]],\n",
       "\n",
       "        [[0.07058824, 0.07058824, 0.07058824, ..., 0.22352941,\n",
       "          0.21568627, 0.21568627],\n",
       "         [0.08235294, 0.08235294, 0.07843137, ..., 0.1254902 ,\n",
       "          0.12156863, 0.11372549],\n",
       "         [0.07843137, 0.07058824, 0.07058824, ..., 0.24313725,\n",
       "          0.24313725, 0.24705882],\n",
       "         ...,\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7372549 ],\n",
       "         [0.15686275, 0.15686275, 0.15686275, ..., 0.74117647,\n",
       "          0.74117647, 0.74117647],\n",
       "         [0.15294118, 0.15294118, 0.15294118, ..., 0.74117647,\n",
       "          0.74117647, 0.74117647]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.17254902, 0.18039216, 0.18823529, ..., 0.35686275,\n",
       "          0.35686275, 0.35686275],\n",
       "         [0.10980392, 0.12156863, 0.1372549 , ..., 0.23921569,\n",
       "          0.25098039, 0.26666667],\n",
       "         [0.18823529, 0.19607843, 0.20392157, ..., 0.36470588,\n",
       "          0.35294118, 0.36078431],\n",
       "         ...,\n",
       "         [0.68627451, 0.68627451, 0.68627451, ..., 0.64705882,\n",
       "          0.65098039, 0.65490196],\n",
       "         [0.68627451, 0.68627451, 0.68627451, ..., 0.6627451 ,\n",
       "          0.6627451 , 0.6627451 ],\n",
       "         [0.68627451, 0.68627451, 0.68627451, ..., 0.65490196,\n",
       "          0.65882353, 0.6627451 ]],\n",
       "\n",
       "        [[0.17254902, 0.15686275, 0.14901961, ..., 0.3372549 ,\n",
       "          0.32941176, 0.32156863],\n",
       "         [0.18039216, 0.18823529, 0.19215686, ..., 0.35686275,\n",
       "          0.35294118, 0.35686275],\n",
       "         [0.20784314, 0.20784314, 0.2       , ..., 0.3372549 ,\n",
       "          0.33333333, 0.3254902 ],\n",
       "         ...,\n",
       "         [0.68627451, 0.68627451, 0.68627451, ..., 0.6627451 ,\n",
       "          0.6627451 , 0.6627451 ],\n",
       "         [0.69019608, 0.69019608, 0.69019608, ..., 0.65882353,\n",
       "          0.65882353, 0.65882353],\n",
       "         [0.68627451, 0.68627451, 0.68627451, ..., 0.6627451 ,\n",
       "          0.6627451 , 0.6627451 ]],\n",
       "\n",
       "        [[0.07058824, 0.0745098 , 0.07843137, ..., 0.12156863,\n",
       "          0.10980392, 0.09411765],\n",
       "         [0.18823529, 0.18431373, 0.18039216, ..., 0.3372549 ,\n",
       "          0.33333333, 0.3254902 ],\n",
       "         [0.08235294, 0.08627451, 0.08627451, ..., 0.10588235,\n",
       "          0.09803922, 0.09411765],\n",
       "         ...,\n",
       "         [0.69019608, 0.69019608, 0.69019608, ..., 0.6627451 ,\n",
       "          0.6627451 , 0.6627451 ],\n",
       "         [0.69803922, 0.69803922, 0.69803922, ..., 0.6627451 ,\n",
       "          0.6627451 , 0.6627451 ],\n",
       "         [0.68627451, 0.68627451, 0.69019608, ..., 0.6627451 ,\n",
       "          0.65882353, 0.65882353]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bcc90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [y]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1b9f0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17fe7350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 61, 800, 800)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26aee31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 81.7405\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 50.3697\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 36.3254\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 27.5382\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.0899\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 14.7081\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.1694\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.6507\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.7367\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.4430\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.5717\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8210\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1611\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5585\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0414\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6474\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3281\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0802\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8976\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7490\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6239\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5177\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4283\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3526\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2870\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2371\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1964\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1615\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1314\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1053\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0833\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0649\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0497\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0372\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0269\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0187\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0122\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0074\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0042\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0022\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0013\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0014\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0021\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0031\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0043\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0077\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0086\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fc9bc6f08>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(60, kernel_size=(2,2), input_shape=(1, 60, 800, 800)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52c91af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020FC541FE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "794c63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a4d14",
   "metadata": {},
   "source": [
    "# Grayscale Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c68b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/92/_804j2_s6cb9ytq1q1j27h500000gn/T/ipykernel_11633/3539040688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# converting to gray-scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# write to gray-scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "source = cv2.VideoCapture(score_df.iloc[0][0])\n",
    "# We need to set resolutions. \n",
    "# so, convert them from float to integer. \n",
    "frame_width = int(source.get(3)) \n",
    "frame_height = int(source.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "result = cv2.VideoWriter('gray.avi',  \n",
    "            cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "            30, size, 0) \n",
    "  \n",
    "# running the loop \n",
    "while True: \n",
    "  \n",
    "    # extracting the frames \n",
    "    ret, img = source.read() \n",
    "      \n",
    "    # converting to gray-scale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # write to gray-scale \n",
    "    result.write(gray)\n",
    "\n",
    "    # displaying the video \n",
    "    cv2.imshow(\"Live\", gray) \n",
    "  \n",
    "    # exiting the loop \n",
    "    key = cv2.waitKey(1) \n",
    "    if key == ord(\"q\"): \n",
    "        break\n",
    "# closing the window \n",
    "cv2.destroyAllWindows() \n",
    "source.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
